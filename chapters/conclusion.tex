\chapter{Conclusion and Prospects}

\label{chap:concl}
\section {Conclusion}
This master thesis has presented a prototypical solution for incremental speech
recognizer combination of Google and Sphinx. 
%The described implementation has shown a better timing in comparison to Google.
% 

Incremental speech recognizer is possible to run in 2 modes: alignment only and
alignment + recognition. Incremental results, coming from Google, have been
aligned using forced alignment IU module and Sphinx ASR. Evaluation of
alignment  results quality have shown that Google + Sphinx combination produces
missing in Google alone timing information. The quality of Google+Sphinx
alignment is comparable to the alignment of the Sphinx alone. Under the
assumption that processing time of Sphinx, which depends on computational power,
could have been neglected, Google+Sphinx in the alignment mode is competitive
with Google in its performance. 

To overcome the Google latency two 2 approaches have been tested.  The first one
uses a combination of alignment and JSGF grammar. The second one combines the
alignment and n-gram grammars.  In both cases the search graph consists of two
connected parts. The first part  represent results, coming from Google.
The second contains the nodes, reconstructed from the
corresponding grammar types. Moreover the tests have proved that, using a n-gram
grammar it is possible to reduce the search space in the second part of the
graph by modifying the search path, depending on Google hypotheses. 

Finally, timeliness of Google, Sphinx and Google+Sphinx results have been
analysed. Evaluation has shown that Google+Sphinx in alignment+recognition mode
has shown an improvement in comparison to Google alone and Google+Sphinx in
alignment mode. Timeliness quality growth in alignment+recognition mode is
explained by the possibility of Google+Sphinx to deliver intermediate
recognition results while waiting for Google hypotheses. 

\section {Future Prospects}
Present implementation has shown some limitations, that could be seen
as a task for future research.

First, Google+Sphinx uses an offset, produced by Google, for the calculation of the file length, sent to 
Sphinx for alignment. For future there should be considered a possibility to implement a data
processor that measures how many samples of audio  have been already sent to
Google.  These measurements as well as the first alignment results, coming from
Google+Sphinx should be use as the basis for the calculation of the length of the audio to be sent to Google+Sphinx for 
optimal alignment and recognition.

Second, tests have shown that Sphinx+Google in alignment and recognition mode,
using bigger language, shows drawbacks in comparison to configurations with smaller
language models. At the same time smaller models have their limitation with the
larger sets of data.  It order to get in improvement in implementation is is
necessary to investigate the possibilities of less time consuming loading of
dynamic language models.

Third, present timing calculations of the Sphinx recognizer with dynamic flat
linguist should be improved within InproTK. Such improvement will guarantee
sequential timing labelling of the results in the first part of the graph in
the combined mode.

Moreover, for JSGF grammar there is a possibility to develop an improved
phone-loop model and to look at the problem of the words and phonemes
interchangeability, while doing timing and timeliness analyses. 

Finally, present implementation is extendable to other types of audio formats
apart from wave format as well as for different audio sources, such as microphone speech. 



